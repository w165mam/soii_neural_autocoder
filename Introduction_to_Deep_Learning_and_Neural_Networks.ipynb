{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/w165mam/soii_neural_autocoder/blob/master/Introduction_to_Deep_Learning_and_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkodPOiLLdog"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUfTgilkLdoj"
      },
      "source": [
        "# Deep Learning and Neural Networks\n",
        "\n",
        "Deep learning is a subfield of machine learning that seeks to solve problems by learning intermediate data representations. The primary algorithm for deep learning is the deep neural network, and if you've been following developments in Artificial Intelligence over the last decade you have probably heard a lot about them. Among its many recent accomplishments, deep learning techniques are now directly responsible the recent and very dramatic advances in image recognition, speech recognition, and language understanding.\n",
        "\n",
        "Unfortunately, as you will soon see, deep neural networks also much more difficult to build than the models we have seen so far in class. Among the many challenges:\n",
        "1. Deep neural networks often require extraordinary amounts of computation\n",
        "2. Effective training of deep neural networks often relies on a wide variety of poorly understood heuristics\n",
        "3. Deep neural networks tends to have a much larger number of hyperparameters requiring expert tuning\n",
        "\n",
        "We can only partially address the first problem in this class. Specifically, BLS now has a small number of high-end GPU's (Graphical Processing Units). A GPU is basically a very cheap super-computer, optimized for linear algebra operations. Each contains several thousand simple computers with ultra-fast memory interfaces between them so they can rapidly exchange and aggregate information.\n",
        "\n",
        "We will be using these GPU's for our experiments. If you wish to train deep neural networks outside of BLS, Google makes free GPU's available through [Google Colab](https://colab.research.google.com/). GPU's are also relatively affordable, a good buying guide for deep learning applications is available [here](https://blog.slavv.com/picking-a-gpu-for-deep-learning-3d4795c273b9). You are also free to try training neural networks without GPU acceleration, but be warned, unless you are building something very simple, you will be waiting a long time.\n",
        "\n",
        "One consequence of the deep neural networks' exotic hardware needs is that we will also need new software capable of using that hardware. We will use the `tensorflow` library, which is the most popular tool for training deep neural networks. We will also be using the `keras` library, which is a simplified interface on top of tensorflow. A reasonable alternative is the `PyTorch` library, but we will not cover that in this class.\n",
        "\n",
        "# What is a deep neural network?\n",
        "\n",
        "A deep neural network is just an extension of logistic regression, which itself is just an extension of linear regression. Recall the basic equation for a simple linear regression. If the inputs are represented by the variables $x_1, x_2, ..., x_i$, and the weights controlling the influence of these inputs is represented by $w_1, w_2, ..., w_i$ then the equation for linear regression is:\n",
        "\n",
        "$y=w_1x_1 + w_2x_2 + ... + w_ix_i$\n",
        "\n",
        "As we saw in logistic regression, we can modify this one step further, by passing the entire output through the logistic function $f(z)=\\frac{1}{1+e^{-z}}$. This has the effect of contraining the output to be between 0 and 1. Our equation now becomes:\n",
        "\n",
        "$y=f(w_1x_1 + w_2x_2 + ... + w_ix_i)$\n",
        "\n",
        "If we draw this in graphical form, with three inputs, it resembles the following:\n",
        "\n",
        "![logistic regression](https://github.com/ameasure/colab_tutorials/blob/master/Images/artificial%20neuron.png?raw=1)\n",
        "\n",
        "From this perspective, logistic regression shares some similarities with the biological neuron. Like a biological neuron, logistic regression receives inputs from a variety of sources. Like a biological neuron, the influence of these inputs seems to be controlled by the strengths of the connections (represented by weights, in logistic regression). And like a biological neuron, the logistic regression uses this information to produce an output. Hence, an alternate interpretation of logistic regression, the artificial neuron. In neural network speak, this neuron has 4 key components:\n",
        "* three inputs ($x_1, x_2, x_3$)\n",
        "* three weights ($w_1, w_2, w_3$)\n",
        "* an acitivation function ($f(w,x)$, in this case the `logistic` function)\n",
        "* an output (a.k.a. activation) ($y$)\n",
        "\n",
        "Logistic regression does not, of course, acquire any magical new powers by simply changing its name. But interesting things start to happen as we extend our metaphor. What happens when we start connecting these artificial neurons to other artificial neurons, i.e. using the outputs of some neurons and inputs to others?\n",
        "\n",
        "Although we can connect our neural networks in all sorts of patterns, for computational convenience it is common to organize our artificial neurons into layers, and design our neural network by describing how our various layers connect to each other.\n",
        "\n",
        "This might sound exotic, but in fact we have already worked with a layer of artificial neurons, we just didn't know it. A single layer of artificial neurons in which each neuron is connected to all inputs and each uses the multinomial logistic function is exactly equivalent to the multinomial logistic regression we have used so extensively in this class. We will soon see however, that by connecting these layers to other layers, we can address a wide variety of issues we struggled with before. One thing that does not change however, is the fundamental process by which we calculate the weights of our artificial neural network. We still use gradient descent, specifically the following algorithm:\n",
        "1. Randomly initialize the weights of our neurons to small values.\n",
        "2. Choose a loss function (some measure of how poorly our model is predicting the training data)\n",
        "3. Calculate the model's loss on the training data\n",
        "4. Update the weights in the direction that reduces loss (using calculus)\n",
        "5. Repeat steps 3 and 4 until we're happy with the network's performance\n",
        "\n",
        "\n",
        "# Feed Forward Neural Network\n",
        "Enough talk, lets start by building one of the simplest possible neural networks, a feed forward neural network with 1 hidden layer and 1 output layer. Visually, this resembles the following (but with more neurons in each layer).\n",
        "\n",
        "![neural_network](https://github.com/ameasure/colab_tutorials/blob/master/Images/feed_forward_network_wikipedia_300px.png?raw=1)\n",
        "\n",
        "# Note for Colab Users:\n",
        "If you're running this in Google Colab make sure you open up the **Runtime** tab, select **Change runtime type** and select **GPU** as the hardware accelerator. This will make the following computations run much faster. You will also need to execute the following command to copy the msha data to your Colab instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3t7QWSKOrgN",
        "outputId": "53c7d3b9-7951-4e3f-f425-2e70d8cfc513",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!wget --no-clobber 'https://github.com/ameasure/autocoding-class/raw/master/msha.xlsx'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ‘msha.xlsx’ already there; not retrieving.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92YeiO4sLdok"
      },
      "source": [
        "### Preparing the data\n",
        "We'll use our MSHA data to train our first neural network. The process of preparing the training data is mostly similar to the process we used for scikit-learn, with one key difference. Unlike scikit-learn, Keras requires the outputs (the y-values) to be in matrix format where each row corresponds to a training example, each column corresponds to a part-of-body-code, and the column containing the correct code has a value of 1 and the others have a value of 0. Scikit-learn constructed this matrix for us behind the scenes automatically. We can easily perform the same operation for Keras using scikit-learn's LabelBinarizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8sRKziKLdol",
        "outputId": "b8604476-6c4f-4ade-a22e-748242df2a23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# read in the data and split it into training and validation\n",
        "df = pd.read_excel('msha.xlsx')\n",
        "df['ACCIDENT_YEAR'] = df['ACCIDENT_DT'].apply(lambda x: x.year)\n",
        "df['ACCIDENT_YEAR'].value_counts()\n",
        "df_train = df[df['ACCIDENT_YEAR'].isin([2010, 2011])].copy()\n",
        "df_valid = df[df['ACCIDENT_YEAR'] == 2012].copy()\n",
        "print('training rows:', len(df_train))\n",
        "print('validation rows:', len(df_valid))\n",
        "\n",
        "# create bag of words features\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(df_train['NARRATIVE'])\n",
        "X_train = vectorizer.transform(df_train['NARRATIVE'])\n",
        "X_valid = vectorizer.transform(df_valid['NARRATIVE'])\n",
        "\n",
        "# keras only accepts a one-hot encoding of the training labels\n",
        "# we do that here\n",
        "label_encoder = LabelBinarizer().fit(df_train['INJ_BODY_PART'])\n",
        "y_train = label_encoder.transform(df_train['INJ_BODY_PART'])\n",
        "y_valid = label_encoder.transform(df_valid['INJ_BODY_PART'])\n",
        "n_codes = len(label_encoder.classes_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training rows: 18681\n",
            "validation rows: 9032\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXwjI5IqLdon",
        "outputId": "d84a4719-ad63-4dd0-d2de-41a67c909326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(y_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18681, 11915)\n",
            "(18681, 46)\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCmFyJspLdor"
      },
      "source": [
        "Define the organization of our neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaR9dIw-Ldos",
        "outputId": "fc909a2b-a525-40dd-b75e-29954e66e2f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input, Dropout, Concatenate\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# First, we create an input layer. This tells keras\n",
        "# what the input data will look like. Specifically, that\n",
        "# the input will contain the same number of columns\n",
        "# as the X_train matrix (i.e. the number of features)\n",
        "text_input = Input(shape=(X_train.shape[1],))\n",
        "# Next, we create the first hidden layer.\n",
        "# Dense means every neuron in this layer is connected to every input\n",
        "# units specifies the number of artificial neurons in this layer\n",
        "# activation indicates the activation function that will be used on each neuron\n",
        "# (text_input) indicates that the layer uses output of the text_input layer as its input\n",
        "layer1 = Dense(units=100, activation='relu')(text_input)\n",
        "# Now we specify the ouput layer\n",
        "# it contains one neuron for each part of body code (we want predctions for these)\n",
        "# each neuron uses the softmax activation so that the outputs mimic probabilities\n",
        "# Note: this is identical to a multinomial logistic regression model\n",
        "output = Dense(units=n_codes, activation='softmax')(layer1)\n",
        "\n",
        "# Finally, we tell Keras which layers are the inputs and outputs of our model\n",
        "model = Model(inputs=[text_input], outputs=[output])\n",
        "\n",
        "# We then tell Keras how we plan to fit the model\n",
        "# optimizer - the algorithm used to calculate the neural network's weights\n",
        "#   specifically, we use a variant of gradient descent called Adam\n",
        "#   with a learning rate of .001\n",
        "# loss - specifices the loss function we will use when updating weights\n",
        "# metrics - specifies the validation metrics we will calculate after each epoch\n",
        "optimizer = Adam(lr=.001)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0625 16:45:41.522207 140393672824704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0625 16:45:41.536523 140393672824704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0625 16:45:41.541007 140393672824704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0625 16:45:41.579016 140393672824704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0625 16:45:41.587526 140393672824704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwkmZeysLdov"
      },
      "source": [
        "Examine the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DCFMS74Ldow",
        "outputId": "fb907bf8-70e8-4486-dc51-b7a7c7a9146e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 11915)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               1191600   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 46)                4646      \n",
            "=================================================================\n",
            "Total params: 1,196,246\n",
            "Trainable params: 1,196,246\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uUiA8o4Ldo2"
      },
      "source": [
        "Now that we have specified our model, we can fit it to our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EtKB0j8Ldo3",
        "outputId": "e0e4918a-9ad5-4229-91b4-bdda63e1ba09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "# x - the training input to our model\n",
        "# y - the training ouput for our model\n",
        "# batch_size - the number of training examples we use for each gradient update\n",
        "# epochs - the number of full cycles through the training data\n",
        "# validation_data - the data we evaluate the model on at the end of each epoch\n",
        "model.fit(x=X_train, y=y_train,\n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=32, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0625 16:45:41.698828 140393672824704 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0625 16:45:41.744944 140393672824704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 18681 samples, validate on 9032 samples\n",
            "Epoch 1/5\n",
            "18681/18681 [==============================] - 5s 250us/step - loss: 1.6969 - acc: 0.6220 - val_loss: 1.0284 - val_acc: 0.7542\n",
            "Epoch 2/5\n",
            "18681/18681 [==============================] - 3s 184us/step - loss: 0.7221 - acc: 0.8237 - val_loss: 0.8976 - val_acc: 0.7624\n",
            "Epoch 3/5\n",
            "18681/18681 [==============================] - 3s 184us/step - loss: 0.4399 - acc: 0.8910 - val_loss: 0.9147 - val_acc: 0.7565\n",
            "Epoch 4/5\n",
            "18681/18681 [==============================] - 4s 188us/step - loss: 0.2911 - acc: 0.9309 - val_loss: 0.9438 - val_acc: 0.7582\n",
            "Epoch 5/5\n",
            "18681/18681 [==============================] - 3s 186us/step - loss: 0.2042 - acc: 0.9539 - val_loss: 1.0058 - val_acc: 0.7471\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fafd1239ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjRDv4XJLdo9"
      },
      "source": [
        "What's going on? It's just gradient descent, the same algorithm we used to calculate the parameters of our models before. The main difference is that Keras is now showing us lots of intermediate outputs. In particular, you can see how the loss of the model changes as we grab a new batch of training examples, calculate the loss, and then update the weights. When we get to the end of each epoch you see Keras calculate the accuracy of the model on the validation data set. We do this so we know when to stop training our model, i.e. when the validation performance starts going down it's time to stop because our model is overfitting to the training data. We can plot the pattern below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99rjV928Ldo-",
        "outputId": "3a448d26-3e60-49a5-abbd-6215257a3453",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('validation accuracy')\n",
        "plt.plot(model.history.history['val_acc'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7faf91016780>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AzPxtC4LdpC"
      },
      "source": [
        "This is a popular technique for determining how long to train neural networks because neural networks tend to be heavily over-parameterized, if you train them for long enough they can pften overfit the training data very easily.\n",
        "\n",
        "# Using the Model\n",
        "As with scikit-learn models, we can generate the predictions and save them to a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKiqQAz8LdpD",
        "outputId": "868fbc12-4441-4f3f-8fae-4da1160d69a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "# get the [n_cases, n_classes] predicted probability matrix\n",
        "prediction_prob_matrix = model.predict(X_valid)\n",
        "# get the classes with the highest predicted probability, save them to our dataframe\n",
        "df_valid['PREDICTED_PART'] = label_encoder.inverse_transform(prediction_prob_matrix)\n",
        "# add the predicted probabilities\n",
        "df_valid['PREDICTED_PROB'] = prediction_prob_matrix.max(axis=1)\n",
        "# take a look at what we've got\n",
        "df_valid.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ACCIDENT_DT</th>\n",
              "      <th>FIPS_STATE_CD</th>\n",
              "      <th>INJ_BODY_PART</th>\n",
              "      <th>INJ_BODY_PART_CD</th>\n",
              "      <th>MINE_ID</th>\n",
              "      <th>NARRATIVE</th>\n",
              "      <th>ACCIDENT_YEAR</th>\n",
              "      <th>PREDICTED_PART</th>\n",
              "      <th>PREDICTED_PROB</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012-08-20</td>\n",
              "      <td>24</td>\n",
              "      <td>HIPS (PELVIS/ORGANS/KIDNEYS/BUTTOCKS)</td>\n",
              "      <td>440</td>\n",
              "      <td>1800761</td>\n",
              "      <td>Employee, parked s/c on grade at 16-Block #3 E...</td>\n",
              "      <td>2012</td>\n",
              "      <td>TRUNK, MULTIPLE PARTS</td>\n",
              "      <td>0.304522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2012-02-21</td>\n",
              "      <td>42</td>\n",
              "      <td>BODY SYSTEMS</td>\n",
              "      <td>600</td>\n",
              "      <td>3600017</td>\n",
              "      <td>Possible heart attack.</td>\n",
              "      <td>2012</td>\n",
              "      <td>BODY SYSTEMS</td>\n",
              "      <td>0.593920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2012-10-03</td>\n",
              "      <td>41</td>\n",
              "      <td>SHOULDERS (COLLARBONE/CLAVICLE/SCAPULA)</td>\n",
              "      <td>450</td>\n",
              "      <td>3503757</td>\n",
              "      <td>Employee was cleaning up plant spillage into a...</td>\n",
              "      <td>2012</td>\n",
              "      <td>SHOULDERS (COLLARBONE/CLAVICLE/SCAPULA)</td>\n",
              "      <td>0.513532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2012-01-23</td>\n",
              "      <td>17</td>\n",
              "      <td>FINGER(S)/THUMB</td>\n",
              "      <td>340</td>\n",
              "      <td>1103189</td>\n",
              "      <td>Employee was putting a drag on a shuttle car, ...</td>\n",
              "      <td>2012</td>\n",
              "      <td>FINGER(S)/THUMB</td>\n",
              "      <td>0.999987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2012-05-10</td>\n",
              "      <td>42</td>\n",
              "      <td>HAND (NOT WRIST OR FINGERS)</td>\n",
              "      <td>330</td>\n",
              "      <td>4600016</td>\n",
              "      <td>While using a cutting torch to remove a bearin...</td>\n",
              "      <td>2012</td>\n",
              "      <td>HAND (NOT WRIST OR FINGERS)</td>\n",
              "      <td>0.959524</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ACCIDENT_DT  ...  PREDICTED_PROB\n",
              "2   2012-08-20  ...        0.304522\n",
              "5   2012-02-21  ...        0.593920\n",
              "8   2012-10-03  ...        0.513532\n",
              "12  2012-01-23  ...        0.999987\n",
              "27  2012-05-10  ...        0.959524\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcI2qU3ILdpG"
      },
      "source": [
        "# Regularization\n",
        "\n",
        "Even more so than linear models, neural networks suffer from overfitting. Because they have such a large number of parameters they can easily memorize the data they are trained on. We can use L2-regularization, as we did with our logistic regression models, but for neural networks another popular technique is called `dropout`. In dropout we randomly set the outputs of a fraction of neurons, at each training step, to 0. A popular choice is 50%. This has a strong regularization effect that often improves overall performance. Let's try it out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1LMKxLcLdpH",
        "outputId": "e8a662e5-ece3-49ef-fdef-fa6f885e1480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "text_input = Input(shape=(X_train.shape[1],))\n",
        "layer1 = Dense(units=100, activation='relu')(text_input)\n",
        "dropout = Dropout(0.5)(layer1)\n",
        "output = Dense(units=len(label_encoder.classes_), activation='softmax')(dropout)\n",
        "# specify the inputs and outputs of our model\n",
        "# input is the raw text features\n",
        "# output is the predicted probabilities\n",
        "do_model = Model(inputs=[text_input], outputs=[output])\n",
        "# specify the algorithm for calculating weights 'adam'\n",
        "# specify the loss function 'categorical_crossentropy'\n",
        "# specify the validation metrics we will calculate after each epoch\n",
        "optimizer = Adam(lr=.001)\n",
        "do_model.compile(optimizer=optimizer,\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "do_model.fit(x=X_train, y=y_train,\n",
        "            validation_data=(X_valid, y_valid),\n",
        "            batch_size=32, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0625 16:46:01.346240 140393672824704 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 18681 samples, validate on 9032 samples\n",
            "Epoch 1/5\n",
            "18681/18681 [==============================] - 4s 217us/step - loss: 1.9898 - acc: 0.5402 - val_loss: 1.1738 - val_acc: 0.7260\n",
            "Epoch 2/5\n",
            "18681/18681 [==============================] - 4s 199us/step - loss: 1.0470 - acc: 0.7481 - val_loss: 0.9203 - val_acc: 0.7679\n",
            "Epoch 3/5\n",
            "18681/18681 [==============================] - 4s 197us/step - loss: 0.7753 - acc: 0.8085 - val_loss: 0.8553 - val_acc: 0.7748\n",
            "Epoch 4/5\n",
            "18681/18681 [==============================] - 4s 200us/step - loss: 0.6129 - acc: 0.8427 - val_loss: 0.8443 - val_acc: 0.7755\n",
            "Epoch 5/5\n",
            "18681/18681 [==============================] - 4s 199us/step - loss: 0.5019 - acc: 0.8687 - val_loss: 0.8537 - val_acc: 0.7742\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faf90650518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kZI4n-3hi9f"
      },
      "source": [
        "prediction_prob_matrix = do_model.predict(X_valid)\n",
        "df_valid['PREDICTED_PART'] = label_encoder.inverse_transform(prediction_prob_matrix)\n",
        "df_valid['PREDICTED_PROB'] = prediction_prob_matrix.max(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEdr0St1LdpK",
        "outputId": "52e12f8f-0234-4c8d-d4c6-3b0fc7a8c08a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "plt.ylabel('validation accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.plot(do_model.history.history['val_acc'], label='with dropout')\n",
        "plt.plot(model.history.history['val_acc'], label='without dropout')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7faf90282b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDu8JeZrLdpQ"
      },
      "source": [
        "As you can see, adding dropout improved the overall performance of our model and decreased overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4mQC6oynGaT"
      },
      "source": [
        "# Uncertainty Estimates and \"Bayesian Neural Networks\"\n",
        "We have already seen that our model's probability scores give us one useful measure of uncertainty, but there is an important caveat. The model's probability scores only reflect uncertainty observed in the training data, not uncertainty that we have learned the appropriate model. This uncertainty might seem unmeasurable, but in fact it is, and [Yarin Gal and collaborators](https://arxiv.org/pdf/1506.02142.pdf) have shown that by training a neural network model with dropout we have incidentally implemented a popular Bayesian technique for doing exactly this. To get uncertainty estimates all we need to do is leave dropout enabled during prediction and generate multiple predictions for each observation. The distribution of the resulting predictions gives us an estimate of the uncertainty associated with our model. We illustrate this below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1HZSEbndDI",
        "outputId": "40d685fd-a68e-4dfb-cda9-4fd06cb2797b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# create a dropout layer that stays on even during prediction\n",
        "class MCDropout(keras.layers.Dropout):\n",
        "  def call(self, inputs):\n",
        "    return super().call(inputs, training=True)\n",
        "\n",
        "# create a dropout model that keeps dropout on\n",
        "mc_text_input = Input(shape=(X_train.shape[1],))\n",
        "mc_layer1 = Dense(units=100, activation='relu')(mc_text_input)\n",
        "mc_dropout = MCDropout(0.5)(mc_layer1)\n",
        "mc_output = Dense(units=len(label_encoder.classes_), activation='softmax')(mc_dropout)\n",
        "mc_model = Model(inputs=[mc_text_input], outputs=[mc_output])\n",
        "optimizer = Adam(lr=.001)\n",
        "mc_model.compile(optimizer=optimizer,\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "mc_model.fit(x=X_train, y=y_train,\n",
        "             validation_data=(X_valid, y_valid),\n",
        "             batch_size=32, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 18681 samples, validate on 9032 samples\n",
            "Epoch 1/5\n",
            "18681/18681 [==============================] - 4s 213us/step - loss: 1.9910 - acc: 0.5427 - val_loss: 1.3067 - val_acc: 0.6933\n",
            "Epoch 2/5\n",
            "18681/18681 [==============================] - 4s 196us/step - loss: 1.0552 - acc: 0.7461 - val_loss: 1.0515 - val_acc: 0.7411\n",
            "Epoch 3/5\n",
            "18681/18681 [==============================] - 4s 198us/step - loss: 0.7746 - acc: 0.8093 - val_loss: 0.9797 - val_acc: 0.7496\n",
            "Epoch 4/5\n",
            "18681/18681 [==============================] - 4s 199us/step - loss: 0.6105 - acc: 0.8443 - val_loss: 0.9953 - val_acc: 0.7463\n",
            "Epoch 5/5\n",
            "18681/18681 [==============================] - 4s 196us/step - loss: 0.5027 - acc: 0.8688 - val_loss: 1.0162 - val_acc: 0.7446\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faf90220e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wSuD92LIrVJ"
      },
      "source": [
        "# sample predictions from our model [n_pred, n_obs, n_codes]\n",
        "y_probas = np.stack([mc_model.predict(X_valid) for sample in range(100)])\n",
        "# recover the \"best predictions\" by averaging over the predicted probabilities\n",
        "y_prob = y_probas.mean(axis=0)\n",
        "# we can also recover the standard deviations\n",
        "y_std = y_probas.std(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apNCoVnwjiX-"
      },
      "source": [
        "Below, we visualize the probability distributions for random narratives in our validation data.atives."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5unyPF0saJyW",
        "outputId": "47374037-7589-4c63-ff06-c6c458b42457",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "\n",
        "# grab a random narrative in our validation set\n",
        "obs_index = random.randint(0, len(df_valid))\n",
        "# display the narrative\n",
        "print(df_valid.iloc[obs_index]['NARRATIVE'])\n",
        "# get the predicted code (the highest probability code as averaged over our samples)\n",
        "pred_code = label_encoder.inverse_transform(y_prob)[obs_index]\n",
        "print('PREDICTED:', pred_code)\n",
        "# get the correct code\n",
        "print('CORRECT:', df_valid.iloc[obs_index]['INJ_BODY_PART'])\n",
        "code_index = y_prob.argmax(axis=1)[obs_index]\n",
        "# display the mean probability associated with that code\n",
        "print('PROB:', y_prob[obs_index][code_index])\n",
        "# display the standard deviation associated with our sample probabilities\n",
        "print('STD:', y_std[obs_index][code_index])\n",
        "# create a histogram of the sampled probabilities for this code\n",
        "n, bins, patches = plt.hist(y_probas[:, obs_index, code_index])\n",
        "plt.xlim(0,1)\n",
        "txt = plt.title(f'Histogram of P(code={pred_code})')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Employee reported that when he was stepping out of young buggy, he turned to walk away & twisted his ankle when he stepped on a rock. He thought he was ok until later in day (5:15pm) he noticed his ankle was swollen. We took him to medic, then to ER. Doctor issued restrictions.\n",
            "PREDICTED: ANKLE\n",
            "CORRECT: ANKLE\n",
            "PROB: 0.9936971\n",
            "STD: 0.014043883\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEICAYAAABVv+9nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nST1lwEtST/1/1KnJwMI1nysAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86bR6Ubg-oWa"
      },
      "source": [
        "# get the standard deviation just for the predicted code\n",
        "y_pred_std = y_std[range(len(y_prob)), y_prob.argmax(axis=1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQfZrXKU0-Jz",
        "outputId": "1f30e50b-c43f-4034-e3f7-2e6454e98429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        }
      },
      "source": [
        "df_valid['BAYES_PRED'] = label_encoder.inverse_transform(y_prob)\n",
        "df_valid['BAYES_PROB'] = y_prob.max(axis=1)\n",
        "df_valid['BAYES_STD'] = np.round(y_pred_std, 2)\n",
        "df_valid[['NARRATIVE', 'PREDICTED_PART', 'PREDICTED_PROB',\n",
        "          'BAYES_PRED', 'BAYES_PROB', 'BAYES_STD']].sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NARRATIVE</th>\n",
              "      <th>PREDICTED_PART</th>\n",
              "      <th>PREDICTED_PROB</th>\n",
              "      <th>BAYES_PRED</th>\n",
              "      <th>BAYES_PROB</th>\n",
              "      <th>BAYES_STD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15196</th>\n",
              "      <td>EE was taking back cover off engine compartmen...</td>\n",
              "      <td>FINGER(S)/THUMB</td>\n",
              "      <td>0.991273</td>\n",
              "      <td>FINGER(S)/THUMB</td>\n",
              "      <td>0.982416</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37651</th>\n",
              "      <td>Diagnosed with Noise Induced Hearing Loss of 0...</td>\n",
              "      <td>EAR(S) INTERNAL &amp; HEARING</td>\n",
              "      <td>0.999574</td>\n",
              "      <td>EAR(S) INTERNAL &amp; HEARING</td>\n",
              "      <td>0.993225</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12628</th>\n",
              "      <td>The miner was performing the routine task of c...</td>\n",
              "      <td>KNEE/PATELLA</td>\n",
              "      <td>0.993153</td>\n",
              "      <td>KNEE/PATELLA</td>\n",
              "      <td>0.958642</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13177</th>\n",
              "      <td>Employee was pulling a water hose, and slipped...</td>\n",
              "      <td>BACK (MUSCLES/SPINE/S-CORD/TAILBONE)</td>\n",
              "      <td>0.326105</td>\n",
              "      <td>BACK (MUSCLES/SPINE/S-CORD/TAILBONE)</td>\n",
              "      <td>0.375066</td>\n",
              "      <td>0.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15209</th>\n",
              "      <td>Employee was cutting a rock dust bag when the ...</td>\n",
              "      <td>HAND (NOT WRIST OR FINGERS)</td>\n",
              "      <td>0.576142</td>\n",
              "      <td>HAND (NOT WRIST OR FINGERS)</td>\n",
              "      <td>0.516808</td>\n",
              "      <td>0.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33895</th>\n",
              "      <td>The employee was doing the walk around inspect...</td>\n",
              "      <td>ANKLE</td>\n",
              "      <td>0.700591</td>\n",
              "      <td>ANKLE</td>\n",
              "      <td>0.708067</td>\n",
              "      <td>0.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38077</th>\n",
              "      <td>While changing cat tracks on the Bobcat, he wa...</td>\n",
              "      <td>FINGER(S)/THUMB</td>\n",
              "      <td>0.999996</td>\n",
              "      <td>FINGER(S)/THUMB</td>\n",
              "      <td>0.999933</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17737</th>\n",
              "      <td>Received a CWP claim for employee on 4/10/2012</td>\n",
              "      <td>CHEST (RIBS/BREAST BONE/CHEST ORGNS)</td>\n",
              "      <td>0.692692</td>\n",
              "      <td>CHEST (RIBS/BREAST BONE/CHEST ORGNS)</td>\n",
              "      <td>0.699599</td>\n",
              "      <td>0.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21344</th>\n",
              "      <td>EE at job site watching turbine pump. EE felt ...</td>\n",
              "      <td>BODY SYSTEMS</td>\n",
              "      <td>0.995118</td>\n",
              "      <td>BODY SYSTEMS</td>\n",
              "      <td>0.988378</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19492</th>\n",
              "      <td>The Blast Crew was preparing for a development...</td>\n",
              "      <td>WRIST</td>\n",
              "      <td>0.993229</td>\n",
              "      <td>WRIST</td>\n",
              "      <td>0.977233</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               NARRATIVE  ... BAYES_STD\n",
              "15196  EE was taking back cover off engine compartmen...  ...      0.02\n",
              "37651  Diagnosed with Noise Induced Hearing Loss of 0...  ...      0.01\n",
              "12628  The miner was performing the routine task of c...  ...      0.06\n",
              "13177  Employee was pulling a water hose, and slipped...  ...      0.16\n",
              "15209  Employee was cutting a rock dust bag when the ...  ...      0.27\n",
              "33895  The employee was doing the walk around inspect...  ...      0.17\n",
              "38077  While changing cat tracks on the Bobcat, he wa...  ...      0.00\n",
              "17737     Received a CWP claim for employee on 4/10/2012  ...      0.15\n",
              "21344  EE at job site watching turbine pump. EE felt ...  ...      0.02\n",
              "19492  The Blast Crew was preparing for a development...  ...      0.09\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "PGpqI_-_LdpQ"
      },
      "source": [
        "# When and why do deep neural networks work?\n",
        "It's still a mystery, but hints are starting to emerge. For example, [[1]](https://arxiv.org/pdf/1608.08225.pdf) points out that hierarchical and compositional relationships are very common in nature and deep neural networks can represent these relationships with exponentially fewer parameters than shallow networks (linear models). It can also be shown that neural networks are universal function approximators, in other words they can approximate any relationship between inputs and outputs to any degree of precision.\n",
        "\n",
        "In general, deep neural networks seem to work best on tasks where the input contains large amounts of extraneous noise, such as image and speech understanding (not math or logic)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FerKuE__12Q"
      },
      "source": [
        "# Next Lesson\n",
        "\n",
        "[Convolutional Neural Networks](https://colab.research.google.com/drive/1Bck3x0znv61uDSkZIT5pAdO_oyWaUPup)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD_IolOG_uem"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}